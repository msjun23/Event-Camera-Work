# GPU precision: ['highest', 'high', 'medium'], for more details
# https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision
gpu_precision: medium
# See Docs for full flags and descriptions
# https://pytorch-lightning.readthedocs.io/en/stable/common/trainer.html#trainer-class-api
trainer:
  params:
    max_epochs: 200
    accelerator: gpu
    strategy: auto
    precision: bf16-mixed       # 32-true (32) for default, bf16-mixed for mixed precision
    accumulate_grad_batches: 1  # Gradient accumulation every n batches
    gradient_clip_val: null
    log_every_n_steps: 10
    check_val_every_n_epoch: 1
    limit_train_batches: 1.0    # train on full dataset, can be used to toggle quick run
    limit_val_batches: 1.0      # validate on full dataset, can be used to toggle quick run, 0.0 means no validation
    enable_model_summary: True  # Model summary before training process
dataset:
  dir: /root/data/
  # name: [MVSEC, DSEC]
  name: MVSEC
  params:
    # split: ['1', '2', '3']
    split: '1'
    # modality: [event, image, EI]
    modality: EI
    # representation: [voxel, on_off, raw]
    representation: raw
    delta_t_ms: 50
    # minimal event accumulation time = delta_t_ms / num_bins [ms]
    num_bins: 25
    # original size: [260, 346]
    height: 260
    width: 346
    crop_height: 256
    crop_width: 336
    pad_height: 272
    pad_width: 352
show:
  train: False
  validation: False
  test: False
model:
  name: StereoDepthLightningModule
  event_processor:
    params:
      in_channels: 25
      base_channels: 8
  disparity_estimator:
    params:
      in_channels: 2
      max_disp: 120
      refine_channels: 2
  optimizer:
    name: Adam
    params:
      lr: 0.0005
      weight_decay: 0.0001
  scheduler:
    name: CosineAnnealingWarmupRestarts
    params:
      cycle_mult: 1.0
      first_cycle_steps: 100
      gamma: 1.0
      lr_ratio: 0.0001
      warmup_steps: 10
  dataloader:
    train:
      params:
        batch_size: 64
        shuffle: True
        drop_last: False
        num_workers: 8
    validation:
      params:
        batch_size: 1
        shuffle: False
        drop_last: False
        num_workers: 8
    test:
      params:
        batch_size: 1
        shuffle: False
        drop_last: False
        num_workers: 8